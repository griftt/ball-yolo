import os
import cv2
import time
import logging
import threading
import subprocess
import queue
import numpy as np
from collections import deque, defaultdict
from ultralytics import YOLO
from tqdm import tqdm

# ==================== âš™ï¸ é…ç½®åŒºåŸŸ ====================

# 1. â±ï¸ æ—¶é—´è®¾ç½®
START_FROM_MINUTES = 5.0    # ä»è§†é¢‘çš„ç¬¬å‡ åˆ†é’Ÿå¼€å§‹æ£€æµ‹ï¼Ÿ(å¦‚ 12.5)
MAX_PROCESS_MINUTES = 5    # å¾€åæ£€æµ‹å¤šä¹…ï¼Ÿ

# 2. ğŸ¬ å‰ªè¾‘è§„åˆ™ (ä½ çš„æ–°éœ€æ±‚)
CLIP_PRE_TIME = 5.0         # è¿›çƒå‰ 5 ç§’
CLIP_POST_TIME = 2.0        # è¿›çƒå 2 ç§’
SHOT_COOLDOWN = 3.0         # è¿›çƒåå†·å´æ—¶é—´ (é˜²æ­¢é‡å¤è§¦å‘)

# 3. ğŸ€ ç‰©ç†å¤–æŒ‚ (ç¯®ç­åæ ‡)
# [x1, y1, x2, y2] - å³ä½¿è§†é¢‘ä¸­é€”ç¯®ç­è¢«é®æŒ¡ä¹Ÿèƒ½è¯†åˆ«
LOCKED_HOOP_COORDS = [845, 88, 1023, 172]

# 4. è·¯å¾„ä¸æ¨¡å‹
MODEL_PATH = "./runs/train/yolo11_hd_optimized/weights/best.pt"
VIDEO_PATH = "/Users/grifftwu/Desktop/å†å²ç¯®çƒ/1122/ball.mov"
OUTPUT_DIR = "./outputs/realtime_clips"

# 5. æ¨ç†å‚æ•°
CONF_THRES_BALL = 0.25      # æä½é—¨æ§›
INFERENCE_SIZE = 1024       
FRAME_STEP = 1              # 1=æœ€å‡†, 2=æ›´å¿«
CLS_BALL = 0

# ==================== ğŸš€ ç³»ç»Ÿåˆå§‹åŒ– ====================
os.makedirs(OUTPUT_DIR, exist_ok=True)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger("ultralytics").setLevel(logging.ERROR)

class ClipWorker(threading.Thread):
    """
    åå°å‰ªè¾‘å·¥äººï¼šä¸€æ—¦æ”¶åˆ°ä»»åŠ¡ï¼Œç«‹åˆ»æ‰§è¡Œ FFmpegï¼Œç»ä¸æ‹–å»¶
    """
    def __init__(self, task_queue):
        super().__init__()
        self.task_queue = task_queue
        self.daemon = True 
        self.running = True

    def run(self):
        while self.running:
            try:
                task = self.task_queue.get(timeout=1) 
            except queue.Empty:
                continue

            if task is None: break

            source, start, duration, out_path = task
            
            try:
                # FFmpeg æé€Ÿå‰ªè¾‘
                # æ³¨æ„ï¼šå¯¹äºæœ¬åœ°æ–‡ä»¶ï¼Œffmpeg å¯ä»¥ç›´æ¥åˆ‡å‡ºæœªæ¥çš„2ç§’ï¼Œä¸éœ€è¦ç­‰å¾…
                cmd = [
                    "ffmpeg", "-nostdin", "-y",
                    "-ss", f"{start:.3f}",
                    "-i", source,
                    "-t", f"{duration:.3f}",
                    "-c", "copy",                # æµå¤åˆ¶ï¼Œæ¯«ç§’çº§é€Ÿåº¦
                    "-avoid_negative_ts", "1",
                    "-loglevel", "error",
                    out_path
                ]
                subprocess.run(cmd, check=True)
                
                # ğŸŸ¢ å‰ªè¾‘å®Œæˆï¼Œç«‹åˆ»åœ¨æ§åˆ¶å°åé¦ˆï¼Œä¸ç”¨ç­‰ä¸»ç¨‹åºè·‘å®Œ
                filename = os.path.basename(out_path)
                tqdm.write(f"âœ… [è§†é¢‘ç”Ÿæˆ] {filename} (å‰{CLIP_PRE_TIME}s + å{CLIP_POST_TIME}s)")
                
            except Exception as e:
                logger.error(f"âŒ å‰ªè¾‘å‡ºé”™: {e}")
            finally:
                self.task_queue.task_done()

class RealtimeDetector:
    def __init__(self, model_path, video_path, start_min, duration_min):
        self.video_path = video_path
        
        # å¯åŠ¨åå°å‰ªè¾‘çº¿ç¨‹
        self.clip_queue = queue.Queue()
        self.worker = ClipWorker(self.clip_queue)
        self.worker.start()
        
        print(f"âš¡ï¸ åŠ è½½æ¨¡å‹ (M3 Pro)...")
        self.model = YOLO(model_path)
        
        self.cap = cv2.VideoCapture(video_path)
        self.fps = self.cap.get(cv2.CAP_PROP_FPS) or 30.0
        total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # è·³è½¬æ—¶é—´
        self.start_frame = int(start_min * 60 * self.fps)
        if self.start_frame >= total_frames:
            print("âŒ èµ·å§‹æ—¶é—´è¶…è¿‡è§†é¢‘é•¿åº¦")
            exit()
            
        print(f"â© è·³è½¬è‡³: {start_min}åˆ† ({self.start_frame}å¸§)")
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.start_frame)
        
        # è®¡ç®—ç»“æŸç‚¹
        if duration_min is None:
            self.end_frame = total_frames
        else:
            self.end_frame = min(total_frames, self.start_frame + int(duration_min * 60 * self.fps))
            
        # çŠ¶æ€æœºæ•°æ®
        self.ball_tracks = defaultdict(lambda: {
            'state': 0, 'history': deque(maxlen=40), 
            'last_update_ts': 0, 'max_height': float('inf')
        })
        
        self.locked_hoop_box = np.array(LOCKED_HOOP_COORDS)
        self.last_shot_time = -10
        self.shot_count = 0

    def run(self):
        print(f"ğŸš€ å¼€å§‹æ£€æµ‹ | è§„åˆ™: è¿›çƒæ—¶åˆ» [ å‰{CLIP_PRE_TIME}s ~ å{CLIP_POST_TIME}s ]")
        
        frames_to_process = self.end_frame - self.start_frame
        pbar = tqdm(total=frames_to_process, unit="frame", ncols=100)
        
        current_frame_idx = self.start_frame
        
        try:
            while True:
                if current_frame_idx >= self.end_frame: break

                ret, frame = self.cap.read()
                if not ret: break
                
                # è·³å¸§
                if current_frame_idx % FRAME_STEP != 0:
                    current_frame_idx += 1
                    pbar.update(1)
                    continue
                
                current_time = current_frame_idx / self.fps
                
                # æ¨ç† (åªçœ‹çƒ)
                results = self.model.track(
                    frame, persist=True, verbose=False, 
                    conf=0.01, iou=0.5, imgsz=INFERENCE_SIZE, 
                    classes=[CLS_BALL], device='mps'
                )
                
                self._run_logic(results, current_time)

                pbar.update(FRAME_STEP)
                current_frame_idx += 1
                
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­...")
        finally:
            pbar.close()
            self.cap.release()
            self.shutdown()

    def _run_logic(self, results, current_time):
        if results[0].boxes.id is not None:
            boxes = results[0].boxes
            ids = boxes.id.cpu().numpy().astype(int)
            coords = boxes.xyxy.cpu().numpy()
            confs = boxes.conf.cpu().numpy()
            
            for i, conf in enumerate(confs):
                if conf > CONF_THRES_BALL:
                    ball_id = ids[i]
                    ball_box = coords[i]
                    if self.check_logic(ball_id, ball_box, current_time):
                        self.trigger_goal(current_time)

    def check_logic(self, ball_id, ball_box, current_time):
        if current_time - self.last_shot_time < SHOT_COOLDOWN: return False
        
        track = self.ball_tracks[ball_id]
        bx, by = (ball_box[0]+ball_box[2])/2, (ball_box[1]+ball_box[3])/2
        track['history'].append((int(bx), int(by)))
        track['last_update_ts'] = current_time
        
        hx1, hy1, hx2, hy2 = self.locked_hoop_box
        prev_y = track['history'][-2][1] if len(track['history']) > 1 else by
        curr_y = by
        
        # çŠ¶æ€æœºé€»è¾‘
        if track['state'] == 0:
            if curr_y < prev_y and curr_y < (hy2 + 150):
                track['state'] = 1
                track['max_height'] = curr_y

        elif track['state'] == 1:
            track['max_height'] = min(track['max_height'], curr_y)
            if curr_y > prev_y + 1: 
                hoop_center_y = (hy1 + hy2) / 2
                if track['max_height'] < hoop_center_y + 80:
                    track['state'] = 2
                else:
                    track['state'] = 0

        elif track['state'] == 2:
            hit_x = (hx1 - 40) < bx < (hx2 + 40)
            hit_y = hy1 < by < hy2 + 40
            if hit_x and hit_y:
                track['state'] = 0
                return True # ğŸ¯ è§¦å‘è¿›çƒï¼
            if by > hy2 + 200: track['state'] = 0
        
        if current_time - track['last_update_ts'] > 2.0: track['state'] = 0
        return False

    def trigger_goal(self, current_time):
        """è¿›çƒåï¼Œç«‹å³è®¡ç®—æ—¶é—´æ®µå¹¶å‘é€å‰ªè¾‘ä»»åŠ¡"""
        self.shot_count += 1
        self.last_shot_time = current_time
        
        tqdm.write(f"ğŸ€ [è¿›çƒè§¦å‘] æ—¶é—´: {current_time:.2f}s | æ­£åœ¨å‰ªè¾‘ (å‰{CLIP_PRE_TIME}s+å{CLIP_POST_TIME}s)...")
        
        filename = f"goal_{self.shot_count:03d}_{int(current_time)}s.mp4"
        save_path = os.path.join(OUTPUT_DIR, filename)
        
        # ğŸŸ¢ æ ¸å¿ƒé€»è¾‘ä¿®æ”¹ï¼š
        # å¼€å§‹æ—¶é—´ = å½“å‰æ—¶é—´ - 5ç§’
        start_cut = max(0, current_time - CLIP_PRE_TIME)
        # æ€»æ—¶é•¿ = 5ç§’ + 2ç§’
        total_duration = CLIP_PRE_TIME + CLIP_POST_TIME
        
        # æ”¾å…¥é˜Ÿåˆ—ï¼Œåå°çº¿ç¨‹ä¼šç«‹åˆ»å¤„ç†
        self.clip_queue.put((self.video_path, start_cut, total_duration, save_path))

    def shutdown(self):
        print(f"\nğŸ æ‰«æç»“æŸï¼å…±å‘ç°: {self.shot_count} ä¸ªè¿›çƒ")
        if not self.clip_queue.empty():
            print(f"â³ ç­‰å¾…æœ€å {self.clip_queue.qsize()} ä¸ªè§†é¢‘ç”Ÿæˆ...")
        
        self.clip_queue.join()
        self.worker.running = False
        print(f"âœ… å…¨éƒ¨å®Œæˆã€‚è¯·æŸ¥çœ‹: {OUTPUT_DIR}")
        subprocess.run(["open", OUTPUT_DIR])

if __name__ == "__main__":
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹: {MODEL_PATH}")
    else:
        detector = RealtimeDetector(
            MODEL_PATH, 
            VIDEO_PATH, 
            start_min=START_FROM_MINUTES, 
            duration_min=MAX_PROCESS_MINUTES
        )
        detector.run()