# -*- coding: utf-8 -*-
import os
import cv2
import time
import logging
import threading
import subprocess
import queue
import numpy as np
import torch
from ultralytics import YOLO
from tqdm import tqdm

# ==================== âš™ï¸ æ ¸å¿ƒé…ç½®åŒºåŸŸ ====================

# 1. â±ï¸ è¿è¡Œæ—¶é—´æ§åˆ¶
START_FROM_MINUTES = 55.0     # ä»è§†é¢‘ç¬¬å‡ åˆ†é’Ÿå¼€å§‹è·‘ï¼Ÿ(ä¾‹å¦‚ 12.5)
MAX_PROCESS_MINUTES = 1     # å¾€åè·‘å¤šä¹…ï¼Ÿ(è®¾ä¸º None åˆ™è·‘å®Œä¸ºæ­¢)

# 2. ğŸ¯ è‡ªåŠ¨æ ¡å‡†å‚æ•°
CONF_THRES_RIM_INIT = 0.50   # ç¯®ç­æ ¡å‡†é—¨æ§› (è¦æ±‚æ¸…æ™°)
CALIBRATION_SAMPLES = 30     # æ”¶é›†å¤šå°‘å¸§ç¯®ç­æ ·æœ¬åé”å®šï¼Ÿ(çº¦1ç§’)

# 3. âš¡ï¸ è¿›çƒé€»è¾‘å‚æ•° (Zone-Based Flash Shot)
# é€»è¾‘ï¼šçƒå¿…é¡»å…ˆå»è¿‡ã€é«˜ç©ºé¢„è­¦åŒºã€‘ï¼Œç„¶ååœ¨ã€æœ‰æ•ˆçª—å£ã€‘å†…è½å…¥ã€å¾—åˆ†åŒºã€‘
HIGH_ZONE_OFFSET = 150       # ç¯®ç­ä¸Šæ²¿å¾€ä¸Š 150px ä¸ºé«˜ç©ºåŒº
GOAL_ZONE_OFFSET = 60        # ç¯®ç­ä¸‹æ²¿å¾€ä¸‹ 60px ä¸ºå¾—åˆ†åŒº
SHOT_WINDOW = 2.0            # é«˜ç©º->å…¥ç½‘çš„æœ€å¤§å…è®¸æ—¶é—´é—´éš”(ç§’)

# 4. ğŸ¬ å‰ªè¾‘å‚æ•°
CLIP_PRE_TIME = 5.0          # è¿›çƒå‰æˆªå–ç§’æ•°
CLIP_POST_TIME = 2.0         # è¿›çƒåæˆªå–ç§’æ•°
SHOT_COOLDOWN = 3.0          # è¿›çƒå†·å´æ—¶é—´(ç§’)

# 5. ğŸ¤– æ¨¡å‹ä¸è·¯å¾„ (è¯·ä¿®æ”¹è¿™é‡Œ)
MODEL_PATH = "./runs/train/yolo11_finetune_new_court/weights/best.pt"
VIDEO_PATH = "/Users/grifftwu/Desktop/å†å²ç¯®çƒ/1112/1112.mov"
OUTPUT_DIR = "./outputs/auto_mps_clips_1112"

# 6. æ¨ç†é…ç½® (é’ˆå¯¹ M3 Pro ä¼˜åŒ–)
CONF_THRES_BALL = 0.2       # æä½é—¨æ§›ï¼Œæ•æ‰æ¨¡ç³Šè™šå½±çƒ
INFERENCE_SIZE = 1024        # é«˜æ¸…æ¨ç†ï¼Œä¿è¯è¿œè·ç¦»å°çƒå¯è§

# ç±»åˆ« ID (æ ¹æ®ä½ çš„è®­ç»ƒé›†)
CLS_BALL = 0
CLS_RIM = 1

# ==================== ç³»ç»Ÿåˆå§‹åŒ– ====================
os.makedirs(OUTPUT_DIR, exist_ok=True)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)
# å±è”½ YOLO å†—ä½™æ—¥å¿—
logging.getLogger("ultralytics").setLevel(logging.ERROR)

class ClipWorker(threading.Thread):
    """åå°å‰ªè¾‘å·¥äººï¼šè´Ÿè´£è°ƒç”¨ FFmpeg å¤„ç†è§†é¢‘é˜Ÿåˆ—"""
    def __init__(self, task_queue):
        super().__init__()
        self.task_queue = task_queue
        self.daemon = True 
        self.running = True

    def run(self):
        while self.running:
            try:
                task = self.task_queue.get(timeout=1) 
            except queue.Empty:
                continue
            if task is None: break
            
            source, start, duration, out_path = task
            try:
                # FFmpeg æé€Ÿæµå‰ªè¾‘ (æ— æŸä¸é‡ç¼–ç )
                cmd = [
                    "ffmpeg", "-nostdin", "-y",
                    "-ss", f"{start:.3f}",
                    "-i", source,
                    "-t", f"{duration:.3f}",
                    "-c", "copy",
                    "-avoid_negative_ts", "1",
                    "-loglevel", "error",
                    out_path
                ]
                subprocess.run(cmd, check=True)
                tqdm.write(f"âœ… [å·²ä¿å­˜] {os.path.basename(out_path)}")
            except Exception as e:
                logger.error(f"âŒ å‰ªè¾‘å‡ºé”™: {e}")
            finally:
                self.task_queue.task_done()

class AutoMPSDetector:
    def __init__(self, model_path, video_path, start_min, duration_min):
        self.video_path = video_path
        
        # åˆå§‹åŒ–é˜Ÿåˆ—
        self.clip_queue = queue.Queue()
        self.worker = ClipWorker(self.clip_queue)
        self.worker.start()
        
        # 1. ç¡¬ä»¶æ£€æŸ¥ (MPS)
        if torch.backends.mps.is_available() and  not MODEL_PATH.endswith(".mlpackage"):
            self.device = 'mps'
            print(f"âš¡ï¸ MPS åŠ é€Ÿå·²å¼€å¯ (M3 Pro æ€§èƒ½å…¨å¼€)")
        else:
            self.device = 'cpu'
            print(f"âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ° MPSï¼Œå°†ä½¿ç”¨ CPU è¿è¡Œ")

        print(f"ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}...")
        self.model = YOLO(model_path)
        
        # GPU é¢„çƒ­ (é˜²æ­¢ç¬¬ä¸€å¸§å¡é¡¿)
        print("ğŸ”¥ æ­£åœ¨é¢„çƒ­ GPU...")
        dummy = np.zeros((INFERENCE_SIZE, INFERENCE_SIZE, 3), dtype=np.uint8)
        self.model.predict(dummy, device=self.device, verbose=False, imgsz=INFERENCE_SIZE)
        
        self.cap = cv2.VideoCapture(video_path)
        self.fps = self.cap.get(cv2.CAP_PROP_FPS) or 30.0
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # è®¡ç®—è·³è½¬å¸§
        self.start_frame = int(start_min * 60 * self.fps)
        if self.start_frame >= self.total_frames:
            print("âŒ èµ·å§‹æ—¶é—´è¶…è¿‡è§†é¢‘æ€»é•¿åº¦")
            exit()
        
        print(f"â© è·³è½¬è‡³: {start_min}åˆ† ({self.start_frame}å¸§)")
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.start_frame)
        
        # è®¡ç®—ç»“æŸå¸§
        if duration_min is None:
            self.end_frame = self.total_frames
        else:
            self.end_frame = min(self.total_frames, self.start_frame + int(duration_min * 60 * self.fps))

        # ğŸŸ¢ è‡ªåŠ¨æ ¡å‡†å˜é‡
        self.is_calibrated = False
        self.calibration_buffer = [] # å­˜å‚¨ç¯®ç­åæ ‡æ ·æœ¬
        self.locked_hoop_box = None  # æœ€ç»ˆé”å®šçš„ç¯®ç­ [x1, y1, x2, y2]
        
        # ğŸŸ¢ è¿›çƒé€»è¾‘å˜é‡
        self.last_high_ball_ts = -10.0  # ä¸Šæ¬¡çƒåœ¨é«˜ç©ºçš„æ—¶é—´
        self.last_shot_ts = -10.0       # ä¸Šæ¬¡è§¦å‘è¿›çƒçš„æ—¶é—´
        self.shot_count = 0
        
        # åŒºåŸŸ (æ ¡å‡†åç”Ÿæˆ)
        self.high_zone_y = 0
        self.goal_zone = []

    def run(self):
        print(f"ğŸš€ å¼€å§‹è¿è¡Œ | åŒºé—´: {START_FROM_MINUTES}åˆ† -> {START_FROM_MINUTES + (MAX_PROCESS_MINUTES or 0)}åˆ†")
        
        process_len = self.end_frame - self.start_frame
        pbar = tqdm(total=process_len, unit="frame", ncols=100)
        current_frame_idx = self.start_frame
        
        try:
            while True:
                # ç»“æŸæ£€æŸ¥
                if current_frame_idx >= self.end_frame: break

                ret, frame = self.cap.read()
                if not ret: break
                
                current_time = current_frame_idx / self.fps
                
                # ğŸŸ¢ æ ¸å¿ƒåˆ†æ”¯ï¼šæ ¡å‡†æ¨¡å¼ vs æ¨ç†æ¨¡å¼
                if not self.is_calibrated:
                    self._run_calibration(frame)
                else:
                    self._run_inference(frame, current_time)

                pbar.update(1)
                current_frame_idx += 1
                
        except KeyboardInterrupt:
            print("\nç”¨æˆ·æ‰‹åŠ¨ä¸­æ–­...")
        finally:
            pbar.close()
            self.cap.release()
            self.shutdown()

    def _run_calibration(self, frame):
        """é˜¶æ®µä¸€ï¼šè‡ªåŠ¨å¯»æ‰¾å¹¶é”å®šç¯®ç­"""
        # åªæ£€æµ‹ç¯®ç­ (Class 1)
        results = self.model.predict(
            frame, verbose=False, conf=0.1, iou=0.5, 
            imgsz=INFERENCE_SIZE, classes=[CLS_RIM], device=self.device
        )
        
        if results[0].boxes is not None and len(results[0].boxes) > 0:
            boxes = results[0].boxes
            best_rim = None
            max_conf = 0.0
            
            # å¯»æ‰¾å½“å‰å¸§ç½®ä¿¡åº¦æœ€é«˜çš„ç¯®ç­
            for box in boxes:
                conf = float(box.conf[0])
                if conf > max_conf:
                    max_conf = conf
                    best_rim = box.xyxy[0].cpu().numpy()
            
            # åªæœ‰ç½®ä¿¡åº¦è¾¾æ ‡æ‰çº³å…¥æ ·æœ¬
            if best_rim is not None and max_conf > CONF_THRES_RIM_INIT:
                self.calibration_buffer.append(best_rim)
                
                if len(self.calibration_buffer) % 10 == 0:
                    tqdm.write(f"ğŸ” æ­£åœ¨æ ¡å‡†ç¯®ç­... ({len(self.calibration_buffer)}/{CALIBRATION_SAMPLES})")

        # æ ·æœ¬è¶³å¤Ÿï¼Œæ‰§è¡Œé”å®š
        if len(self.calibration_buffer) >= CALIBRATION_SAMPLES:
            # å–ä¸­ä½æ•°ï¼Œæ¶ˆé™¤æŠ–åŠ¨
            self.locked_hoop_box = np.median(self.calibration_buffer, axis=0)
            
            # ğŸŸ¢ ç”Ÿæˆåˆ¤å®šåŒºåŸŸ
            x1, y1, x2, y2 = map(int, self.locked_hoop_box)
            
            # 1. é«˜ç©ºè­¦æˆ’çº¿ (ç¯®ç­ä¸Šæ²¿)
            self.high_zone_y = y1 
            
            # 2. å¾—åˆ†åŒºåŸŸ (ç¯®ç­èŒƒå›´ + å‚ç›´å»¶ä¼¸)
            self.goal_zone = [x1 - 20, y1 + 10, x2 + 20, y2 + GOAL_ZONE_OFFSET]
            
            self.is_calibrated = True
            tqdm.write(f"âœ… ç¯®ç­å·²é”å®š! åæ ‡: {self.locked_hoop_box.astype(int)}")
            tqdm.write(f"ğŸš€ åˆ‡æ¢è‡³è¿›çƒæ£€æµ‹æ¨¡å¼ (æé€Ÿç‰ˆ)...")

    def _run_inference(self, frame, current_time):
        """é˜¶æ®µäºŒï¼šæé€Ÿæ£€æµ‹ç¯®çƒ"""
        # åªæ£€æµ‹ç¯®çƒ (Class 0)ï¼Œå¿½ç•¥ç¯®ç­
        results = self.model.predict(
            frame, 
            verbose=False, 
            conf=0.01,           # æä½é—¨æ§›ï¼Œä¸é”™è¿‡ä»»ä½•è™šå½±
            iou=0.5, 
            imgsz=INFERENCE_SIZE, 
            classes=[CLS_BALL],  # åªçœ‹çƒ
            device=self.device
        )
        
        self._check_zones(results, current_time)

    def _check_zones(self, results, current_time):
        """åŒºåŸŸå…³è”é€»è¾‘ï¼šä¸ä¾èµ–è¿ç»­è·Ÿè¸ªï¼Œåªçœ‹æ—¶ç©ºå…³ç³»"""
        # å†·å´æœŸæ£€æŸ¥
        if current_time - self.last_shot_ts < SHOT_COOLDOWN: return

        if results[0].boxes is not None:
            boxes = results[0].boxes
            # ä» GPU è·å–æ•°æ®
            coords = boxes.xyxy.cpu().numpy()
            confs = boxes.conf.cpu().numpy()
            
            ball_in_goal_zone = False
            
            for i, conf in enumerate(confs):
                # è¿‡æ»¤æ‰æä½åˆ†çš„å™ªéŸ³
                if conf > CONF_THRES_BALL:
                    x1, y1, x2, y2 = coords[i]
                    cy = (y1 + y2) / 2
                    cx = (x1 + x2) / 2
                    
                    # 1. æ›´æ–°é«˜ç©ºè®¡æ—¶å™¨
                    # åªè¦æœ‰çƒå‡ºç°åœ¨ç¯®æ¿ä¸Šæ–¹ï¼Œå°±è®¤ä¸ºå¯èƒ½è¦æŠ•ç¯®äº†
                    if cy < self.high_zone_y:
                        self.last_high_ball_ts = current_time
                        
                    # 2. æ£€æŸ¥å¾—åˆ†åŒº
                    gx1, gy1, gx2, gy2 = self.goal_zone
                    if (gx1 < cx < gx2) and (gy1 < cy < gy2):
                        ball_in_goal_zone = True
            
            # âš¡ï¸ åˆ¤å®šæ ¸å¿ƒï¼šç°åœ¨è¿›ç½‘äº† AND ä¸ä¹…å‰åœ¨å¤©ä¸Š
            if ball_in_goal_zone:
                time_diff = current_time - self.last_high_ball_ts
                
                # 0.1s < é—´éš” < 2.0s
                if 0.1 < time_diff < SHOT_WINDOW:
                    self.trigger_goal(current_time)

    def trigger_goal(self, current_time):
        self.shot_count += 1
        self.last_shot_ts = current_time
        
        tqdm.write(f"ğŸ€ [è¿›çƒè§¦å‘] æ—¶é—´: {current_time:.2f}s | No.{self.shot_count}")
        
        # ç”Ÿæˆæ–‡ä»¶å
        filename = f"goal_{self.shot_count:03d}_{int(current_time)}s.mp4"
        save_path = os.path.join(OUTPUT_DIR, filename)
        
        # è®¡ç®—å‰ªè¾‘åŒºé—´
        start_cut = max(0, current_time - CLIP_PRE_TIME)
        duration = CLIP_PRE_TIME + CLIP_POST_TIME
        
        # å‘é€ç»™åå°å·¥äºº
        self.clip_queue.put((self.video_path, start_cut, duration, save_path))

    def shutdown(self):
        print(f"\nğŸ æ‰«æç»“æŸï¼å…±å‘ç°: {self.shot_count} ä¸ªè¿›çƒ")
        if not self.clip_queue.empty():
            print(f"â³ æ­£åœ¨å¤„ç†å‰©ä½™çš„ {self.clip_queue.qsize()} ä¸ªè§†é¢‘ï¼Œè¯·ç¨å€™...")
        
        self.clip_queue.join()
        self.worker.running = False
        print(f"âœ… å…¨éƒ¨å®Œæˆã€‚æ–‡ä»¶å¤¹: {OUTPUT_DIR}")
        # Mac è‡ªåŠ¨æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹
        subprocess.run(["open", OUTPUT_DIR])

if __name__ == "__main__":
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {MODEL_PATH}")
        print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼")
    else:
        detector = AutoMPSDetector(
            MODEL_PATH, 
            VIDEO_PATH, 
            start_min=START_FROM_MINUTES, 
            duration_min=MAX_PROCESS_MINUTES
        )
        detector.run()