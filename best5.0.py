# -*- coding: utf-8 -*-
import os
import cv2
import time
import logging
import threading
import subprocess
import queue
import numpy as np
import torch
from ultralytics import YOLO
from tqdm import tqdm
import psutil 

# ==================== ‚öôÔ∏è Ê†∏ÂøÉÈÖçÁΩÆÂå∫Âüü ====================

# 1. üìÇ ËßÜÈ¢ë‰ªªÂä°ÂàóË°® (ÊîØÊåÅÂ§ö‰∏™Êñá‰ª∂)
# Ê†ºÂºè: {"path": "ËßÜÈ¢ëË∑ØÂæÑ", "start": Ëµ∑ÂßãÂàÜÈíüÊï∞}
VIDEO_TASKS = [
    {
        "path": "/Users/grifftwu/Desktop/ÂéÜÂè≤ÁØÆÁêÉ/1126/111.mp4", 
        "start": 25.25  # ‰æãÂ¶Ç‰∏äÊ¨°Ê£ÄÊµãÂà∞‰∫Ü18ÂàÜ 44Áßí
    },
    {
        "path": "/Users/grifftwu/Desktop/ÂéÜÂè≤ÁØÆÁêÉ/1126/222.mp4", 
        "start": 0.5   # Êñ∞ËßÜÈ¢ë‰ªé 0.5 ÂàÜÈíüÂºÄÂßã
    },
    {
        "path": "/Users/grifftwu/Desktop/ÂéÜÂè≤ÁØÆÁêÉ/1126/333.mp4", 
        "start": 0.5  # ‰æãÂ¶Ç‰∏äÊ¨°Ê£ÄÊµãÂà∞‰∫Ü13ÂàÜ50ÁßíÔºåËøôÈáåÂ°´13.8ÁªßÁª≠
    },
    {
        "path": "/Users/grifftwu/Desktop/ÂéÜÂè≤ÁØÆÁêÉ/1126/444.mp4", 
        "start": 0.5   # Êñ∞ËßÜÈ¢ë‰ªé 0.5 ÂàÜÈíüÂºÄÂßã
    },
    {
        "path": "/Users/grifftwu/Desktop/ÂéÜÂè≤ÁØÆÁêÉ/1126/555.mp4", 
        "start": 0.5  # ‰æãÂ¶Ç‰∏äÊ¨°Ê£ÄÊµãÂà∞‰∫Ü13ÂàÜ50ÁßíÔºåËøôÈáåÂ°´13.8ÁªßÁª≠
    },
    
     

    # ‰Ω†ÂèØ‰ª•ÁªßÁª≠Ê∑ªÂä†Êõ¥Â§ö...
]



# 2. ‚è±Ô∏è ÂÖ®Â±ÄÈÖçÁΩÆ
MAX_PROCESS_MINUTES = 30     # ÊØè‰∏™ËßÜÈ¢ëÊúÄÂ§öÊ£ÄÊµãÂ§öÂ∞ëÂàÜÈíü (ËÆæ‰∏∫ None ÂàôÊ£ÄÊµãÂà∞ÁªìÂ∞æ)
OUTPUT_DIR = "./outputs/auto_mps_clips_batch_01"

# 3. ‚öôÔ∏è ÊÄßËÉΩ‰ºòÂåñÈÖçÁΩÆ (ÈíàÂØπ‰Ω†ÁöÑ M3 Pro + 1024Ê®°Âûã)
INFERENCE_SIZE = 1024        # ‚ö†Ô∏è ‰øùÊåÅÂíå‰Ω†ËÆ≠ÁªÉÊó∂ÁöÑÂ∞∫ÂØ∏‰∏ÄËá¥Ôºå‰∏çË¶ÅÊîπ
FRAME_SKIP = 3               # ‚ö°Ô∏è Ë∑≥Â∏ß‰ºòÂåñ: ÊØè 3 Â∏ßÊ£ÄÊµã‰∏ÄÊ¨° (Â§ßÂπÖÊèêÈÄü)
ROTATE_VIDEO_180 = False     # ÊòØÂê¶ÊóãËΩ¨ÁîªÈù¢

# 4. üéØ Ëá™Âä®Ê†°ÂáÜ‰∏éÂà§ÂÆöÂèÇÊï∞
CONF_THRES_RIM_INIT = 0.40   
CALIBRATION_SAMPLES = 30     
HIGH_ZONE_OFFSET = 150       
GOAL_ZONE_OFFSET = 150       
SHOT_WINDOW = 2.5            
CONF_THRES_BALL = 0.15       
CLS_BALL = 0
CLS_RIM = 1

# 5. üé¨ Ââ™ËæëÂèÇÊï∞
CLIP_PRE_TIME = 4.0          
CLIP_POST_TIME = 2.0         
SHOT_COOLDOWN = 2.0          

# 6. ü§ñ Ê®°ÂûãË∑ØÂæÑ
MODEL_PATH = "./runs/train/yolo11_finetune_new_court/weights/best.mlpackage"



# ==================== Á≥ªÁªüÂàùÂßãÂåñ ====================
os.makedirs(OUTPUT_DIR, exist_ok=True)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)
logging.getLogger("ultralytics").setLevel(logging.ERROR)

class ClipWorker(threading.Thread):
    def __init__(self, task_queue, rotate_flag):
        super().__init__()
        self.task_queue = task_queue
        self.rotate_flag = rotate_flag
        self.daemon = True 
        self.running = True

    def run(self):
        while self.running:
            try:
                task = self.task_queue.get(timeout=1) 
            except queue.Empty:
                continue
            if task is None: break
            
            source, start, duration, out_path = task
            self.process_video(source, start, duration, out_path)
            self.task_queue.task_done()

    def process_video(self, source, start, duration, out_path):
        try:
            cmd = [
                "ffmpeg", "-nostdin", "-y",
                "-ss", f"{start:.3f}",
                "-i", source,
                "-t", f"{duration:.3f}",
                "-loglevel", "error"
            ]

            if self.rotate_flag:
                cmd.extend([
                    "-vf", "transpose=2,transpose=2", 
                    "-c:v", "libx264", "-preset", "ultrafast", "-c:a", "copy"
                ])
            else:
                cmd.extend(["-c", "copy", "-avoid_negative_ts", "1"])

            cmd.append(out_path)
            subprocess.run(cmd, check=True)
            tqdm.write(f"‚úÖ [Â∑≤‰øùÂ≠ò] {os.path.basename(out_path)}")
        except Exception as e:
            logger.error(f"‚ùå Ââ™ËæëÂá∫Èîô: {e}")

class AutoMPSDetector:
    def __init__(self, loaded_model, device, video_path, start_min, duration_min):
        """
        ÂàùÂßãÂåñÂèòÂä®: Áé∞Âú®Êé•Êî∂Â∑≤ÁªèÂä†ËΩΩÂ•ΩÁöÑ model ÂØπË±°ÔºåËÄå‰∏çÊòØË∑ØÂæÑ
        """
        self.model = loaded_model
        self.device = device
        self.video_path = video_path
        
        self.clip_queue = queue.Queue()
        self.worker = ClipWorker(self.clip_queue, ROTATE_VIDEO_180)
        self.worker.start()
        
        # È¢ÑÁÉ≠ (‰ΩøÁî®ËæÉÂ∞èÁöÑÂ∞∫ÂØ∏È¢ÑÁÉ≠Ôºå‰ªÖ‰∏∫‰∫ÜÂî§ÈÜíÁÆ°ÈÅì)
        dummy = np.zeros((640, 640, 3), dtype=np.uint8)
        self.model.predict(dummy, device=self.device, verbose=False, imgsz=INFERENCE_SIZE)
        
        self.cap = cv2.VideoCapture(video_path)
        self.fps = self.cap.get(cv2.CAP_PROP_FPS) or 30.0
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        self.start_frame = int(start_min * 60 * self.fps)
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.start_frame)
        
        if duration_min is None:
            self.end_frame = self.total_frames
        else:
            self.end_frame = min(self.total_frames, self.start_frame + int(duration_min * 60 * self.fps))

        # ÈÄªËæëÂèòÈáè
        self.is_calibrated = False
        self.calibration_buffer = [] 
        self.locked_hoop_box = None  
        self.last_interaction_ts = -10.0
        self.last_shot_ts = -10.0       
        self.shot_count = 0
        self.rim_box = []
        self.high_line = 0
        self.goal_zone = []

        # Resize ‰ºòÂåñ
        self.original_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.original_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        # Áõ¥Êé•Áº©ÊîæÂà∞Ê®°ÂûãÈúÄË¶ÅÁöÑ 1024 ÂÆΩÔºåÂáèÂ∞ëÊ®°ÂûãÂÜÖÈÉ®Â§ÑÁêÜÂéãÂäõ
        self.resize_scale = INFERENCE_SIZE / self.original_width
        self.detect_w = INFERENCE_SIZE
        self.detect_h = int(self.original_height * self.resize_scale)

   



    def run(self):
        video_name = os.path.basename(self.video_path)
        print(f"\nüé¨ Ê≠£Âú®Â§ÑÁêÜ: {video_name} | Ë∑≥Â∏ß: {FRAME_SKIP}")
        
        process_len = self.end_frame - self.start_frame
        # ÂÆΩ‰∏ÄÁÇπÁöÑËøõÂ∫¶Êù°Ôºå‰ª•‰æøÊòæÁ§∫Êõ¥Â§ö‰ø°ÊÅØ
        pbar = tqdm(total=process_len, unit="frame", ncols=120) 
        current_frame_idx = self.start_frame
        
        # Êï£ÁÉ≠ & ÁõëÊéß ËÆ°Êó∂Âô®
        job_start_time = time.time()
        last_rest_time = time.time()
        
        #‰ª•Ê≠§ËøõÁ®ãÂØπË±°ÁõëÊéßËá™Ë∫´ÂÜÖÂ≠ò
        current_process = psutil.Process(os.getpid())
        
        try:
            while True:
                if current_frame_idx >= self.end_frame: break

               
            
                # =======================================================

                ret, frame = self.cap.read()
                if not ret: break
                
                # ==================== üìä ÂÆûÊó∂Áä∂ÊÄÅÊòæÁ§∫ (Êó∂Èó¥ + ÂÜÖÂ≠ò) ====================
                # ÊØè 10 Â∏ßÊõ¥Êñ∞‰∏ÄÊ¨°ÊòæÁ§∫ÔºåÈÅøÂÖçÂà∑Êñ∞Â§™Âø´Áúã‰∏çÊ∏Ö
                if current_frame_idx % 10 == 0:
                    current_time = current_frame_idx / self.fps
                    mins = int(current_time // 60)
                    secs = int(current_time % 60)
                    
                    # 1. Ëé∑ÂèñÊú¨ËÑöÊú¨Âç†Áî®ÁöÑÂÜÖÂ≠ò (GB)
                    mem_info = current_process.memory_info()
                    script_mem_gb = mem_info.rss / (1024 ** 3) 
                    
                    # 2. Ëé∑ÂèñÁ≥ªÁªüÊÄªÂÜÖÂ≠ò‰ΩøÁî®Áéá (%)
                    sys_mem_percent = psutil.virtual_memory().percent
                    
                    # 3. ÁªÑÂêàÊòæÁ§∫Â≠óÁ¨¶‰∏≤
                    # Ê†ºÂºè: üîç [14:20] | üêè 1.2G/85%
                    # Ëß£Èáä: ËßÜÈ¢ëËøõÂ∫¶ | ËÑöÊú¨Âç†‰∫Ü1.2GÂÜÖÂ≠ò / Á≥ªÁªüÊÄªÂÜÖÂ≠òÁî®‰∫Ü85%
                    
                    # ‚ö†Ô∏è ÂÜÖÂ≠òÈ¢ÑË≠¶È¢úËâ≤: Â¶ÇÊûúÁ≥ªÁªüÂÜÖÂ≠ò > 90%ÔºåÊ∑ªÂä†‰∏Ä‰∏™Ë≠¶ÂëäÊ†áËÆ∞
                    warn_sign = "‚ö†Ô∏è" if sys_mem_percent > 90 else "üêè"
                    
                    desc_str = f"üîç [{mins:02d}:{secs:02d}] | {warn_sign} {script_mem_gb:.1f}GB / {sys_mem_percent}%"
                    pbar.set_description(desc_str)
                # =================================================================

                # Ë∑≥Â∏ß‰ºòÂåñ
                if current_frame_idx % FRAME_SKIP != 0 and self.is_calibrated:
                    current_frame_idx += 1
                    pbar.update(1)
                    continue

                # ÈôçÈááÊ†∑
                detect_frame = cv2.resize(frame, (self.detect_w, self.detect_h), interpolation=cv2.INTER_LINEAR)
                if ROTATE_VIDEO_180:
                    detect_frame = cv2.rotate(detect_frame, cv2.ROTATE_180)
                
                if not self.is_calibrated:
                    self._run_calibration(detect_frame)
                else:
                    current_time = current_frame_idx / self.fps # Á°Æ‰øù‰º†ÁªôÊé®ÁêÜÁöÑÊó∂Èó¥‰πüÊòØÂáÜÁ°ÆÁöÑ
                    self._run_inference(detect_frame, current_time)

                pbar.update(1)
                current_frame_idx += 1
                
        except KeyboardInterrupt:
            pbar.close()
            stop_time = current_frame_idx / self.fps
            stop_min = stop_time / 60.0
            
            print(f"\n\nüõë [ÂΩìÂâçÊñá‰ª∂‰∏≠Êñ≠] {video_name}")
            print(f"üìå ‰∏≠Êñ≠Êó∂Èó¥ÁÇπ: {int(stop_time//60)}ÂàÜ {int(stop_time%60)}Áßí")
            print(f"üëâ ËØ•Êñá‰ª∂ÊÅ¢Â§çÂèÇÊï∞: \"path\": \"{self.video_path}\", \"start\": {max(0, stop_min - 0.1):.2f}")
            
            self.shutdown()
            raise KeyboardInterrupt

        finally:
            if not pbar.disable: pbar.close()
            self.cap.release()
            self.shutdown()

    def _run_calibration(self, frame):
        results = self.model.predict(
            frame, verbose=False, conf=0.1, iou=0.5, 
            imgsz=INFERENCE_SIZE, classes=[CLS_RIM], device=self.device
        )
        if results[0].boxes is not None and len(results[0].boxes) > 0:
            boxes = results[0].boxes
            best_rim = None
            max_conf = 0.0
            for box in boxes:
                conf = float(box.conf[0])
                if conf > max_conf:
                    max_conf = conf
                    best_rim = box.xyxy[0].cpu().numpy()
            if best_rim is not None and max_conf > CONF_THRES_RIM_INIT:
                self.calibration_buffer.append(best_rim)
        if len(self.calibration_buffer) >= CALIBRATION_SAMPLES:
            self.locked_hoop_box = np.median(self.calibration_buffer, axis=0)
            x1, y1, x2, y2 = map(int, self.locked_hoop_box)
            self.rim_box = [x1 - 10, y1 - 10, x2 + 10, y2 + 10]
            self.high_line = y1  
            self.goal_zone = [x1 - 30, y1 + 10, x2 + 30, y2 + GOAL_ZONE_OFFSET]
            self.is_calibrated = True
            tqdm.write(f"‚úÖ ÁØÆÁ≠êÈîÅÂÆö! ÂùêÊ†á: {self.locked_hoop_box.astype(int)}")

    def _run_inference(self, frame, current_time):
        results = self.model.predict(
            frame, verbose=False, conf=0.01, iou=0.5, 
            imgsz=INFERENCE_SIZE, classes=[CLS_BALL], device=self.device
        )
        self._check_zones_optimized(results, current_time)

    def _check_zones_optimized(self, results, current_time):
        if current_time - self.last_shot_ts < SHOT_COOLDOWN: return
        if results[0].boxes is not None:
            boxes = results[0].boxes
            coords = boxes.xyxy.cpu().numpy()
            confs = boxes.conf.cpu().numpy()
            ball_in_goal = False
            for i, conf in enumerate(confs):
                if conf > CONF_THRES_BALL:
                    bx1, by1, bx2, by2 = coords[i]
                    cx = (bx1 + bx2) / 2
                    cy = (by1 + by2) / 2
                    is_high = cy < self.high_line
                    rx1, ry1, rx2, ry2 = self.rim_box
                    is_touching_rim = (rx1 < cx < rx2) and (ry1 < cy < ry2)
                    if is_high or is_touching_rim:
                        self.last_interaction_ts = current_time
                    gx1, gy1, gx2, gy2 = self.goal_zone
                    if (gx1 < cx < gx2) and (gy1 < cy < gy2):
                        ball_in_goal = True
            if ball_in_goal:
                time_diff = current_time - self.last_interaction_ts
                if 0.05 < time_diff < SHOT_WINDOW:
                    self.trigger_goal(current_time)

    def trigger_goal(self, current_time):
        self.shot_count += 1
        self.last_shot_ts = current_time
        video_base = os.path.splitext(os.path.basename(self.video_path))[0]
        tqdm.write(f"üèÄ [ËøõÁêÉ] {video_base} | Êó∂Èó¥: {current_time:.2f}s")
        filename = f"{video_base}_goal_{self.shot_count:03d}_{int(current_time)}s.mp4"
        save_path = os.path.join(OUTPUT_DIR, filename)
        start_cut = max(0, current_time - CLIP_PRE_TIME)
        duration = CLIP_PRE_TIME + CLIP_POST_TIME
        self.clip_queue.put((self.video_path, start_cut, duration, save_path))

    def shutdown(self):
        if self.worker.running:
            if not self.clip_queue.empty():
                print(f"‚è≥ Ê≠£Âú®ÂÆåÊàêÂâ©‰ΩôÂâ™Ëæë‰ªªÂä°...")
            self.clip_queue.join()
            self.worker.running = False

# ==================== ‰∏ªÊéßÂà∂ÊµÅÁ®ã ====================
if __name__ == "__main__":
    if not os.path.exists(MODEL_PATH):
        print(f"‚ùå ÈîôËØØ: Êâæ‰∏çÂà∞Ê®°Âûã {MODEL_PATH}")
        exit()

    # 1. Áªü‰∏ÄÂä†ËΩΩÊ®°Âûã (Âè™Âä†ËΩΩ‰∏ÄÊ¨°ÔºåËäÇÁúÅÊòæÂ≠òÂíåÊó∂Èó¥)
    print("üì¶ Ê≠£Âú®Âä†ËΩΩ YOLO Ê®°Âûã...")
    
    # Á°¨‰ª∂Âà§Êñ≠
    device = 'cpu'
    if MODEL_PATH.endswith(".mlpackage"):
        print(f"‚ö†Ô∏è ‰ΩøÁî® CoreML Ê®°Âûã (Neural Engine Âä†ÈÄü)")
    elif torch.backends.mps.is_available():
        device = 'mps'
        print(f"‚ö°Ô∏è MPS Âä†ÈÄüÂ∑≤ÂºÄÂêØ")
    
    loaded_model = YOLO(MODEL_PATH)
    print("‚úÖ Ê®°ÂûãÂä†ËΩΩÂÆåÊØïÔºåÂºÄÂßãÂ§ÑÁêÜ‰ªªÂä°ÂàóË°®...")

    # 2. ÈÅçÂéÜ‰ªªÂä°ÂàóË°®
    try:
        for i, task in enumerate(VIDEO_TASKS):
            path = task["path"]
            start_min = task.get("start", 0.0)
            
            if not os.path.exists(path):
                print(f"‚ö†Ô∏è Ë∑≥ËøáÊó†ÊïàË∑ØÂæÑ: {path}")
                continue

            print(f"\n========================================")
            print(f"üìÇ ‰ªªÂä° [{i+1}/{len(VIDEO_TASKS)}]: {os.path.basename(path)}")
            print(f"‚è±Ô∏è Ëµ∑ÂßãÊó∂Èó¥: {start_min} ÂàÜÈíü")
            print(f"========================================")

            detector = AutoMPSDetector(
                loaded_model, # ‰º†ÂÖ•Â∑≤Âä†ËΩΩÁöÑÊ®°Âûã
                device,
                path, 
                start_min=start_min, 
                duration_min=MAX_PROCESS_MINUTES
            )
            detector.run()
            
        print("\nüéâüéâüéâ ÊâÄÊúâ‰ªªÂä°Â§ÑÁêÜÂÆåÊàêÔºÅ")
        subprocess.run(["open", OUTPUT_DIR])

    except KeyboardInterrupt:
        print("\n\n‚õîÔ∏è ----------------------------------------")
        print("‚õîÔ∏è Áî®Êà∑ÂÖ®Â±Ä‰∏≠Êñ≠ÔºåÁ®ãÂ∫èÂÅúÊ≠¢„ÄÇ")
        print("‚õîÔ∏è ----------------------------------------")