#!/usr/bin/env python3
"""
YOLO æ¨¡å‹è½¬æ¢è„šæœ¬
å°† best.pt è½¬æ¢ä¸ºè·¨å¹³å°æ ¼å¼ï¼ˆONNX / TFLiteï¼‰

ä½¿ç”¨æ–¹æ³•:
1. å®‰è£…ä¾èµ–: pip install ultralytics onnx onnxruntime
2. å°† best.pt æ”¾åœ¨åŒç›®å½•ä¸‹
3. è¿è¡Œ: python convert_model.py
"""

import os
import sys

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
    try:
        from ultralytics import YOLO
        import onnx
        print("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
        return True
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("\nè¯·å…ˆå®‰è£…ä¾èµ–:")
        print("  pip install ultralytics onnx onnxruntime")
        return False

def convert_to_onnx(model_path: str, output_dir: str = "./converted_models"):
    """
    è½¬æ¢ä¸º ONNX æ ¼å¼ï¼ˆiOS + Android é€šç”¨ï¼‰
    """
    from ultralytics import YOLO
    
    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    model = YOLO(model_path)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # å¯¼å‡º ONNX
    print("\nğŸ”„ è½¬æ¢ä¸º ONNX æ ¼å¼...")
    onnx_path = model.export(
        format='onnx',
        imgsz=640,           # è¾“å…¥å°ºå¯¸
        simplify=True,       # ç®€åŒ–æ¨¡å‹
        opset=12,            # ONNX opset ç‰ˆæœ¬
        dynamic=False,       # å›ºå®šè¾“å…¥å°ºå¯¸ï¼ˆç§»åŠ¨ç«¯æ›´ç¨³å®šï¼‰
    )
    
    print(f"âœ… ONNX æ¨¡å‹å·²ä¿å­˜: {onnx_path}")
    return onnx_path

def convert_to_tflite(model_path: str, output_dir: str = "./converted_models"):
    """
    è½¬æ¢ä¸º TensorFlow Lite æ ¼å¼ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
    """
    from ultralytics import YOLO
    
    print(f"\nğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
    model = YOLO(model_path)
    
    os.makedirs(output_dir, exist_ok=True)
    
    print("\nğŸ”„ è½¬æ¢ä¸º TFLite æ ¼å¼...")
    tflite_path = model.export(
        format='tflite',
        imgsz=640,
        int8=False,          # ä¸ä½¿ç”¨ INT8 é‡åŒ–ï¼ˆä¿æŒç²¾åº¦ï¼‰
    )
    
    print(f"âœ… TFLite æ¨¡å‹å·²ä¿å­˜: {tflite_path}")
    return tflite_path

def verify_onnx_model(onnx_path: str):
    """éªŒè¯ ONNX æ¨¡å‹"""
    import onnx
    import onnxruntime as ort
    import numpy as np
    
    print(f"\nğŸ” éªŒè¯ ONNX æ¨¡å‹: {onnx_path}")
    
    # 1. æ£€æŸ¥æ¨¡å‹ç»“æ„
    model = onnx.load(onnx_path)
    onnx.checker.check_model(model)
    print("  âœ… æ¨¡å‹ç»“æ„éªŒè¯é€šè¿‡")
    
    # 2. è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
    print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    for input in model.graph.input:
        shape = [d.dim_value for d in input.type.tensor_type.shape.dim]
        print(f"  è¾“å…¥: {input.name}, å½¢çŠ¶: {shape}")
    
    for output in model.graph.output:
        shape = [d.dim_value for d in output.type.tensor_type.shape.dim]
        print(f"  è¾“å‡º: {output.name}, å½¢çŠ¶: {shape}")
    
    # 3. æµ‹è¯•æ¨ç†
    print("\nğŸ§ª æµ‹è¯•æ¨ç†...")
    session = ort.InferenceSession(onnx_path)
    input_name = session.get_inputs()[0].name
    input_shape = session.get_inputs()[0].shape
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    test_input = np.random.randn(*[1 if isinstance(d, str) else d for d in input_shape]).astype(np.float32)
    
    # è¿è¡Œæ¨ç†
    outputs = session.run(None, {input_name: test_input})
    print(f"  âœ… æ¨ç†æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: {outputs[0].shape}")
    
    return True

def print_usage_guide(onnx_path: str):
    """æ‰“å°ä½¿ç”¨æŒ‡å—"""
    print("\n" + "="*60)
    print("ğŸ‰ æ¨¡å‹è½¬æ¢å®Œæˆï¼")
    print("="*60)
    
    print(f"""
ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:
   {onnx_path}

ğŸ“± Flutter é¡¹ç›®ä½¿ç”¨æ–¹æ³•:

1. å¤åˆ¶æ¨¡å‹åˆ° Flutter é¡¹ç›®:
   cp {onnx_path} your_flutter_project/assets/models/

2. åœ¨ pubspec.yaml ä¸­æ·»åŠ :
   flutter:
     assets:
       - assets/models/best.onnx

3. æ·»åŠ ä¾èµ–:
   dependencies:
     onnxruntime: ^1.16.0

4. åŠ è½½å¹¶ä½¿ç”¨æ¨¡å‹:
   final session = await OrtSession.create('assets/models/best.onnx');

ğŸ“– è¯¦ç»† Flutter é›†æˆä»£ç è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£ã€‚
""")

def main():
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)
    
    # æ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤å½“å‰ç›®å½•ä¸‹çš„ best.ptï¼‰
    model_path = "./runs/train/yolo11n_640_train/weights/best.pt"
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æŒ‡å®šè·¯å¾„
    if len(sys.argv) > 1:
        model_path = sys.argv[1]
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        print("\nè¯·ç¡®ä¿ best.pt åœ¨å½“å‰ç›®å½•ï¼Œæˆ–æŒ‡å®šè·¯å¾„:")
        print("  python convert_model.py /path/to/best.pt")
        sys.exit(1)
    
    print("="*60)
    print("ğŸ€ ç¯®çƒæ£€æµ‹æ¨¡å‹è½¬æ¢å·¥å…·")
    print("="*60)
    print(f"æºæ¨¡å‹: {model_path}")
    
    # è½¬æ¢ä¸º ONNXï¼ˆä¸»è¦æ ¼å¼ï¼‰
    onnx_path = convert_to_onnx(model_path)
    
    # éªŒè¯æ¨¡å‹
    verify_onnx_model(onnx_path)
    
    # æ‰“å°ä½¿ç”¨æŒ‡å—
    print_usage_guide(onnx_path)
    
    # å¯é€‰ï¼šä¹Ÿè½¬æ¢ TFLite
    print("\n" + "-"*60)
    convert_tflite = input("æ˜¯å¦ä¹Ÿè½¬æ¢ä¸º TFLite æ ¼å¼ï¼Ÿ(y/n): ").strip().lower()
    if convert_tflite == 'y':
        convert_to_tflite(model_path)
        print("âœ… TFLite æ¨¡å‹ä¹Ÿå·²ç”Ÿæˆ")

if __name__ == "__main__":
    main()
